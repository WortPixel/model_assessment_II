{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation and selection continued\n",
    "\n",
    "## Block I: Hypothesis testing\n",
    "I.1 The basic ideas<br>\n",
    "I.2 The $\\chi^2$-test<br>\n",
    "I.3 Conceptual problems of hypothesis testing<br>\n",
    "I.4 Practical problems<br>\n",
    "I.5 Gliese 581: A real story how hypothesis testing failed\n",
    "\n",
    "## Block II: Bayesian evidence\n",
    "II.1 Bayesian evidence and Bayes factors<br>\n",
    "II.2 Computing Bayesian evidence in practice<br>\n",
    "II.3 Consistency of Bayesian evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block I: Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 The basic ideas\n",
    "* How can we assess whether some model (a.k.a. hypothesis) fits a given data set, such that we can tolerate the model or have to reject it?\n",
    "* Hypothesis testing adopts the following approach:<br>\n",
    "(1) You fit your model to the given data, to obtain the best-fit parameters.<br>\n",
    "(2) You assess the residuals of the data and the best-fit model.\n",
    "* Only a single hypothesis is tested at a time, the <font color='red'>null hypothesis</font>, which is either rejected or not (absolute assessment). Hypothesis testing is not comparing different models (relative assessment). In particular, you can test a single model without having to specify any alternative.\n",
    "* Since Frequentists refuse priors, distributions over parameters are inaccessible to them. Instead, Frequentists can only work with distributions over data (<font color='red'>likelihood function</font>).\n",
    "* All hypothesis testing looks at the residuals of the best-fit and asks how likely it is (<font color='red'>p-value</font>) that we would obtain such residuals or even more extreme, if the model was actually true.\n",
    "* Since data can have different noise distributions and models can be even more exotic, there is a seemingly infinite number of tests from which one has to pick \"the right one\" that fits the situation at hand. Some examples are: $\\chi^2$-test, false-alarm probabilities, $t$-test, $F$-test, KS-test, $U$-test, signed-rank test, etc.\n",
    "* Example: You have repeatedly measured the radial velocity of some star at different times. You want to know if the star is orbited by exoplanets or not, and if so, by how many exoplanets.<br>\n",
    "First, you test if the star is alone, i.e., the radial velocities all come from some constant plus noise.<br>\n",
    "If that is rejected, you check if constant plus one Kepler orbit fits the data.<br>\n",
    "If that is rejected, you check if constant plus two Kepler orbits fits the data.<br>\n",
    "If that is rejected, you check if constant plus three Kepler orbits fits the data.<br>\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 The $\\chi^2$-test\n",
    "* For a linear model with Gaussian measurement errors, you can obtain an analytic fit result. For that, you can compute the $\\chi^2$ value of the best-fit parameters.\n",
    "* If your linear model was actually true, then the value of $\\chi^2$ would only include random noise (but no systematic errors between data and model). This is given by the <font color='red'>$\\chi^2$ distribution</font>:\n",
    "\\begin{equation}\n",
    "P(\\chi^2|k)=\\frac{1}{2^{k/2}\\Gamma(k/2)} \\left(\\chi^2\\right)^{k/2-1}e^{-\\chi^2/2}\n",
    "\\end{equation}\n",
    "Here $k$ denotes the <font color='red'>number of degrees of freedom</font> and $\\Gamma$ is the gamma function.\n",
    "* The expectation value of $\\chi^2$ under the $\\chi^2$ distribution happens to equal the number of degrees of freedom:\n",
    "\\begin{equation}\n",
    "\\langle\\chi^2\\rangle = \\int_0^\\infty \\chi^2 P(\\chi^2|k)d\\chi^2=k\n",
    "\\end{equation}\n",
    "This is the origin of <font color='red'>reduced $\\chi^2$</font>, $\\chi^2_\\textrm{red}=\\frac{\\chi^2}{k}$, and why a value of reduced $\\chi^2$ of 1 is considered to indicate a model matching the data.\n",
    "* The variance of $\\chi^2$ is $2k$ and the variance of reduced $\\chi^2$ is 2. This is another argument against aiming for $\\chi^2_\\textrm{red}=1$.\n",
    "* Warning: Reduced $\\chi^2$ can only be used if the data have Gaussian noise <i>and</i> the model is linear! If the noise is non-Gaussian, $\\chi^2$ cannot be used at all. If the noise is Gaussian but the model is nonlinear, we may still use $\\chi^2$, but it will <i>not</i> follow the $\\chi^2$ distribution anymore! As a matter of fact, <font color='red'>the concept of degrees of freedom cannot be mathematically defined for nonlinear models</font>. (Remember the model $f(x)=a\\cos(kx+\\phi)$, which has only 3 parameters but infinite complexity.)\n",
    "* Let us have a model with 4 fit parameters and given training data with 24 examples. The degrees of freedom are $k=24-4=20$. Let his model achieve a best-fit $\\chi^2$ value of 30.0. If this model was actually true, what is the chance of getting such a value or worse? We need to integrate the upper tail of the distribution to obtain the $p$-value:\n",
    "\\begin{equation}\n",
    "p=\\int_{30.0}^\\infty P(\\chi^2|k=20)d\\chi^2\n",
    "\\end{equation}\n",
    "<img src=\"chi2_distribution-p-value.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0698536606994\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2 as chi2dist\n",
    "# Define number of degrees of freedom.\n",
    "ndof = 20\n",
    "# Compute p-value via the CDF (p=1-CDF).\n",
    "print 1.0-chi2dist.cdf(30.0, ndof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If a $p$-value is very small, then it is very unlikely that if this model was true it could create such a \"bad\" fit. In such a case, the model is rejected.\n",
    "* Very often, a fixed threshold of 5% is adopted. If the $p$-value is lower than this, the model is rejected.\n",
    "<img src=\"p-value-cartoon.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3 Conceptual problems of hypothesis testing\n",
    "* Hypothesis testing (no matter what flavour) suffers from several conceptual problems. You need to be aware of these in order to avoid misleading conclusions (e.g., incorrect estimate of number of exoplanets).\n",
    "* The very idea of an absolute assessment \"does the model fit the data?\" is questionable.\n",
    "* How can you reject a hypothesis if you have not formulated an alternative?\n",
    "* While a low $p$-value may lead to a rejection, what happens if the $p$-value is not low enough? Failing to reject a model is not the same as accepting it.\n",
    "* Why should unobserved data \"more extreme\" than the observed value be relevant?\n",
    "* Rejecting a model because the data are \"unlikely\" in some sense is odd, since we <i>did</i> get this data. The data could be \"equally unlikely\" under all plausible models.\n",
    "* $p$-values depend on the best-fit parameters, some of which may be necessary to evalute the model but otherwise of no physical interest. More parameters can lead to lower residuals and thus to false conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4 Practical problems\n",
    "* As mentioned before, a threshold of 5% is often adopted to reject model if the $p$-value is too small.\n",
    "* However, what if the $p$-value would shrink as we gathered more data? Then the correct model would eventually get $p<0.05$ if we only collect enough data.\n",
    "* Example: Let us toss a coin. First, we obtain 4 heads out of 10 tosses. Afterwards, we try again and obtain 8 heads out of 20 tosses. The null hypothesis is \"the coin is fair\", i.e., the fraction of heads is $f=0.5$. In this case, the model \"fair coin\" has no fit parameters. For $h$ heads out of $n$ tosses, this model's likelihood is given by:\n",
    "\\begin{equation}\n",
    "P(h|n,f=0.5)=\\frac{h!}{n!(n-h)!}f^h(1-f)^{n-h}\n",
    "=\\frac{h!}{n!(n-h)!}\\left(\\frac{1}{2}\\right)^h\\left(1-\\frac{1}{2}\\right)^{n-h}\n",
    "=\\frac{h!}{n!(n-h)!}\\frac{1}{2^n}\n",
    "\\end{equation}\n",
    "Since both observed fractions are below 50%, the $p$-value is the \"integral\" over the lower tail of the likelihood (\"more extreme data\"):\n",
    "\\begin{equation}\n",
    "p=\\sum_{i=0}^h P(i|n,f=0.5)\n",
    "=\\frac{1}{2^n}\\sum_{i=0}^h \\frac{i!}{n!(n-i)!}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3198918793e-57\n",
      "3.36792346698e-277\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Compute p for given data.\n",
    "def getP(h, n):\n",
    "    p        = math.pow(2.0,-n)\n",
    "    lognfact = math.log(math.factorial(n))  # Compute log(n!) only once.\n",
    "    for i in range(h+1):\n",
    "        # Careful with the numerics of the factorials.\n",
    "        p = p*math.exp(math.log(math.factorial(i)) - lognfact - math.log(math.factorial(n-i)))\n",
    "    return p\n",
    "# Compute p value for \"fair coin\" given 4 heads out of 10 tosses.\n",
    "print getP(4, 10)\n",
    "# Compute p value for \"fair coin\" given 8 heads out of 20 tosses.\n",
    "print getP(8, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Even for the true model, the <font color='red'>$p$-value decreases as the number of data increases</font>.\n",
    "* If you adopt a fixed threshold of, say, 5%, and then you collect more and more data ... your $p$-value will decrease and you will systematically favour ever more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most $p$-values rely on the number of degrees of freedom ($\\chi^2$-test, $F$-test, Student's $t$-test, etc.) which only exists for linear models with Gaussian noise.\n",
    "* $p$-values are <font color='red'>inconsistent estimators</font>, i.e., as the number of training data increases, they do <i>not</i> converge to the \"truth\". This is particularly bad for <font color='red'>nested models</font>, e.g., multiple planetary orbits in radial-velocity measurements.\n",
    "* Let us illustrate this with a simple simulation:<br>\n",
    "The truth is a constant model, $y=0$, in the range $x\\in[-10,10]$.<br>\n",
    "Gaussian noise with $\\sigma=1$ is added (this allows us to simply use the OLS solution).<br>\n",
    "Fit $f(x)=a_0+a_1 x$ to the data via analytic $\\chi^2$ minimisation. Use the $\\chi^2$-test to assess the model.<br>\n",
    "Investigate how the $\\chi^2$-test performs as we get more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f667d66ca10>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGZCAYAAACUvQX8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfxTeOSrubXi0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f667e354450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "from matplotlib import use\n",
    "use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Use scipy's Cholesky decomposition for matrix inversion.\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "# Reset the RNG.\n",
    "numpy.random.seed(1)\n",
    "# Try for various sizes of training samples.\n",
    "TrainSetSize = [5,10,25,50,100,200,400,800]\n",
    "PValueMed    = []\n",
    "PValueLower  = []\n",
    "PValueUpper  = []\n",
    "Nsimu        = 100\n",
    "for N in TrainSetSize:\n",
    "    # Array for holding results of all simulations.\n",
    "    RawPValues = numpy.empty(Nsimu)\n",
    "    for s in range(Nsimu):\n",
    "        # Draw x from uniform interval -10,10.\n",
    "        X = numpy.random.uniform(-10, 10, N)\n",
    "        # Create Y=0 plus Gaussian random noise.\n",
    "        Y = 0.0 + numpy.random.normal(0.0, 1.0, N)\n",
    "        # Build design matrix.\n",
    "        DesignT    = numpy.empty([2,N])\n",
    "        DesignT[0] = 1.0\n",
    "        DesignT[1] = X\n",
    "        Design     = DesignT.T\n",
    "        # Get coefficients using Cholesky decomposition.\n",
    "        DtD      = numpy.dot(DesignT, Design)\n",
    "        DtY      = numpy.dot(DesignT, Y)\n",
    "        cholesky = cho_factor(DtD)\n",
    "        theta    = cho_solve(cholesky, DtY)\n",
    "        # Compute predictions of best-fit model and evaluate chi-2.\n",
    "        prediction = numpy.dot(Design, theta)\n",
    "        residuals  = Y - prediction\n",
    "        chi2       = numpy.dot(residuals,residuals)\n",
    "        # Compute p-value via the CDF (p=1-CDF).\n",
    "        ndof          = N - 2\n",
    "        RawPValues[s] = 1.0 - chi2dist.cdf(chi2, ndof)\n",
    "    # Sort the p-values.\n",
    "    RawPValues = sorted(RawPValues)\n",
    "    # Get median, lower 16% and upper 84% levels.\n",
    "    PValueMed.append(numpy.median(RawPValues))\n",
    "    PValueLower.append(RawPValues[int(round(0.16*(Nsimu-1.0)))])\n",
    "    PValueUpper.append(RawPValues[int(round(0.84*(Nsimu-1.0)))])\n",
    "# Plot how p-value evolves as N increases.\n",
    "plt.figure(1, figsize=(9,6))\n",
    "plt.plot(TrainSetSize, PValueMed, 'o', ms=5, color='black')\n",
    "for n in range(len(TrainSetSize)):\n",
    "    plt.plot([TrainSetSize[n], TrainSetSize[n]], [PValueLower[n],PValueUpper[n]], '-', lw=1, color='black')\n",
    "plt.xscale('log')\n",
    "plt.ylim(0,1)  # p-value is a probability in range [0,1]\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(r'training set size $N$', fontsize=22)\n",
    "plt.ylabel(r'$p$-value', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we increase the amount of training data, the $\\chi^2$-test is incapable of rejecting the incorrect model $f(x)=a_0+a_1 x$, which contains the \"true\" model $f(x)=0$ as a nested model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5 Gliese 581: A real story how hypothesis testing failed\n",
    "* In 2010, results were published that the star Gliese 581 had 6 exoplanets, whereof one was nearly the mass of Earth and within the habitable zone of that star. This caused quite a stir in the community as well as the general public.\n",
    "* The group used the $\\chi^2$-test and false-alarm probabilities. However, using the same data, a Bayesian competitor group only found evidence for 4 exoplanets. Years later, Gliese 581 was found to exhibit star spots. One of the 6 planets was disclaimed and another one is under serious debate. What happened?\n",
    "* First, a planetary orbit is a badly nonlinear model. Therefore, the concept of degrees of freedom is undefinied such that the $\\chi^2$ distribution does not apply and the $\\chi^2$-test cannot be used.\n",
    "* Second, a single Kepler orbit has 4 free parameters (period, semi-major axis, eccentricity, perihelion angle). A model comprised of a constant proper motion of the entire system plus 6 exoplanets thus has a total of $1+6\\cdot 4=25$ parameters. Since the Kepler orbit is of the $\\cos$-form, we know it has high complexity, i.e., there certainly was some overfitting going on, which lead to artificially low residuals.\n",
    "* Third, no alternative model had been formulated. Had the model \"4 exoplanets plus star spots\" been considered, it may have outperformed the \"6 exoplanets\".\n",
    "* Fourth, the group had doubled the amount of data by combining observations from two different instruments. Having more data leads to lower $p$-values. Since they adopted a fixed threshold of 5%, this mislead them to only accept overly complex models.\n",
    "* Hypothesis testing failed in this case because it was incorrectly used and the group was unaware of the pitfals. We cannot blame hypothesis testing itself for that. <font color='red'>You can use hypothesis testing carefully, if you know what you are doing!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block II: Bayesian evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 Bayesian evidence and Bayes factors\n",
    "* Let some data $D$ be given and we have a model $M$. We want to know what is the probability of the model given the data $P(M|D)$. Using Bayes' theorem:\n",
    "\\begin{equation}\n",
    "P(M|D) = \\frac{P(M)P(D|M)}{P(D)}\n",
    "\\end{equation}\n",
    "$P(M|D)$ plays the role of a \"model posterior\".<br>\n",
    "$P(M)$ is a model prior.<br>\n",
    "$P(D|M)$ is the <font color='red'>Bayesian evidence</font>.<br>\n",
    "$P(D)$ is the likelihood of the data irrespective of any model.\n",
    "* Unfortunately, we cannot get $P(D)$ which would require us to consider <i>every</i> possible model. Instead, we take <i>two models</i> $M_1$ and $M_2$ and take their posterior odds-ratio:\n",
    "\\begin{equation}\n",
    "\\frac{P(M_1|D)}{P(M_2|D)} = \\frac{P(M_1)P(D|M_1)}{P(M_2)P(D|M_2)}\n",
    "\\end{equation}\n",
    "Note that $P(D)$ has cancelled out.\n",
    "* If we consider all models to be equally likely a priori (which we do not have to do), then $P(M_1)=P(M_2)$ and we have:\n",
    "\\begin{equation}\n",
    "\\frac{P(M_1|D)}{P(M_2|D)} = \\frac{P(D|M_1)}{P(D|M_2)}\n",
    "\\end{equation}\n",
    "* The evidence ratio $\\frac{P(D|M_1)}{P(D|M_2)}$ is called the <font color='red'>Bayes factor</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computing a Bayes factor always follows the same procedure, whereas hypothesis testing requires us to identify the correct recipe.\n",
    "* Bayes factors draw a <i>comparison</i> of one model vs. another model (relative assessment). Hypothesis testing attempts to assess a model without regard to any other model.\n",
    "* If $\\frac{P(D|M_1)}{P(D|M_2)}=10$ then the data $D$ are ten times more likely to come from model $M_1$ than from $M_2$. Under flat model priors, this implies that model $M_1$ is ten times more probable given the data than $M_2$.\n",
    "* Terminology and thresholds vary, but some rough guidelines are:<br>\n",
    "$\\frac{P(D|M_1)}{P(D|M_2)}=1-3$ ... \"not worth more than a bare mention\"<br>\n",
    "$\\frac{P(D|M_1)}{P(D|M_2)}=3-10$ ... \"$M_1$ provides some evidence against $M_2$\"<br>\n",
    "$\\frac{P(D|M_1)}{P(D|M_3)}=10-100$ ... \"$M_1$ provides strong evidence against $M_2$\"<br>\n",
    "$\\frac{P(D|M_1)}{P(D|M_2)}>100$ ... \"$M_1$ provides decisive evidence against $M_2$\"\n",
    "* Note that $\\frac{P(D|M_1)}{P(D|M_2)}>1$ provides evidence <i>against</i> $M_2$. It does <i>not</i> provide evidence in favour of $M_1$. There could be a third model which we have not tested that would outperform $M_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Computing Bayesian evidence in practice\n",
    "* For given data $D$ and a model $M$ which has parameters $\\theta$, we evaluate the Bayesian evidence through marginalisation:\n",
    "\\begin{equation}\n",
    "P(D|M)=\\int P(D,\\theta|M)d\\theta\n",
    "=\\int P(D|\\theta,M)\\,P(\\theta|M)d\\theta\n",
    "\\end{equation}\n",
    "In simple words: We \"sum up\" the likelihood of the data for all possible parameter values.\n",
    "* Obviously, the <font color='red'>Bayesian evidence depends on the prior</font>.\n",
    "* The model that has the higher \"average likelihood\" is the better one. But due to the integral, any extra parameter introduces extra volume over which you are averaging.\n",
    "<img src=\"interpret-evidence-goodness-of-fit.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In some rare examples, the Bayesian evidence can be computed analytically (for well chosen priors).\n",
    "* Let $M$ be a linear model with parameters $\\vec\\theta$ and design matrix $D$. Let us choose a conjugate prior, i.e., a Gaussian with mean $\\vec\\theta_0$ and covariance matrix $\\Sigma_0$. If we introduce:\n",
    "\\begin{equation}\n",
    "A = D^T\\cdot\\Sigma^{-1}\\cdot D + \\Sigma_0^{-1}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\vec b = D^T\\cdot\\Sigma^{-1}\\cdot\\vec y + \\Sigma_0^{-1}\\cdot\\vec\\theta_0\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "c = \\vec y^T\\cdot\\Sigma^{-1}\\cdot\\vec y + \\vec\\theta_0^T\\cdot\\Sigma_0^{-1}\\cdot\\vec\\theta_0\n",
    "\\end{equation}\n",
    "The Bayesian evidence then has an analytic solution to the integral:\n",
    "\\begin{equation}\n",
    "P(D|M) = \\frac{\\exp\\left[-\\frac{1}{2}\\left(c - \\vec b^T\\cdot A^{-1}\\cdot\\vec b\\right)\\right]}\n",
    "{(2\\pi)^{N/2}\\sqrt{(\\det\\Sigma)(\\det\\Sigma_0)(\\det A)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In general, the Bayesian evidence $P(D|M)=\\int P(D|\\theta,M)\\,P(\\theta|M)d\\theta$ has no analytic solution for its integral and we need to compute it numerically.\n",
    "* If we have only 1-2 fit parameters, we can do this, e.g., using the trapezoidal rule.\n",
    "* If we have more parameters, we need Monte-Carlo integration.\n",
    "* The simplest but least effective approach is to draw random samples from the prior $P(\\theta|M)$ and evaluate the average likelihood:\n",
    "\\begin{equation}\n",
    "P(D|M)\\approx \\frac{1}{S}\\sum_{s=1}^S P(D|\\theta_s,M) \\qquad\\textrm{where}\\qquad \\theta_s\\sim P(\\theta|M)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(D|M_0) = 4.74572901116e-08\n",
      "P(D|M_1) = 3.37524229657e-09\n",
      "BF       = 14.0604098733\n"
     ]
    }
   ],
   "source": [
    "# Reset random seed.\n",
    "numpy.random.seed(1)\n",
    "# Create some toy data: X in [-10, 10], Y=0 with Gaussian noise sigma=1.\n",
    "N = 10\n",
    "X = numpy.random.uniform(-10, 10, N)\n",
    "Y = 0.0 + numpy.random.normal(0.0, 1.0, N)\n",
    "# Compute average likelihood from Monte-Carlo sampling.\n",
    "S             = 1000\n",
    "Likelihood0th = numpy.empty(S)  # Store likelihoods for 0tu-order model\n",
    "Likelihood1st = numpy.empty(S)  # Store likelihoods for 1st-order model\n",
    "for s in range(S):\n",
    "    # Draw parameters from prior\n",
    "    a0,a1 = numpy.random.normal(0.0, 1.0, 2)\n",
    "    # Compute chi2 for 0th-order model f(x)=a0.\n",
    "    residual = Y - a0\n",
    "    chi2     = numpy.dot(residual,residual)\n",
    "    # Compute likelihood.\n",
    "    Likelihood0th[s] = math.exp(-chi2/2.0)/math.pow(2.0*numpy.pi, N/2.0)\n",
    "    # Compute chi2 for 1st-order model f(x)=a0 + a1*x.\n",
    "    residual = Y - a0 - a1*X\n",
    "    chi2     = numpy.dot(residual,residual)\n",
    "    # Compute likelihood.\n",
    "    Likelihood1st[s] = math.exp(-chi2/2.0)/math.pow(2.0*numpy.pi, N/2.0)\n",
    "# Print evidence estimates and Bayes factor.\n",
    "print \"P(D|M_0) = \"+str(numpy.mean(Likelihood0th))\n",
    "print \"P(D|M_1) = \"+str(numpy.mean(Likelihood1st))\n",
    "print \"BF       = \"+str(numpy.mean(Likelihood0th)/numpy.mean(Likelihood1st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(D|M_0) = 4.83710018576e-08\n",
      "P(D|M_1) = 3.63787272385e-09\n",
      "BF       = 13.2965074727\n"
     ]
    }
   ],
   "source": [
    "# Compute the Bayesian evidence analytically.\n",
    "# Step 1: Compute the analytic evidence for M_1: f(x) = a_0.\n",
    "# Build design matrix.\n",
    "DesignT    = numpy.empty([1,N])\n",
    "DesignT[0] = 1.0\n",
    "Design     = DesignT.T\n",
    "# Define matrix A, vector b and scalar c. Note that theta_0=0.\n",
    "A = numpy.dot(DesignT, Design) + numpy.identity(1)\n",
    "b = numpy.dot(DesignT, Y)\n",
    "c = numpy.dot(Y, Y)\n",
    "# Use a trick to get inverse matrix from more stable Cholesky decomposition.\n",
    "cholesky = cho_factor(A)\n",
    "Ainv     = cho_solve(cholesky, numpy.identity(1))\n",
    "# Compute log-evidence of second model. Drop irrelevant normalisation constants.\n",
    "detSigma  = 1.0\n",
    "detSigma0 = 1.0\n",
    "logEvi0   = -0.5*c + 0.5*numpy.dot(b, numpy.dot(Ainv, b))\n",
    "logEvi0   = logEvi0 - 0.5*math.log(numpy.linalg.det(A)) - 0.5*math.log(detSigma) - 0.5*math.log(detSigma0)\n",
    "evidence0 = math.exp(logEvi0 - 0.5*N*math.log(2.0*numpy.pi))\n",
    "# Step 2: Compute the analytic evidence for M_2: f(x) = a_0+a_1*x.\n",
    "# Build design matrix.\n",
    "DesignT    = numpy.empty([2,N])\n",
    "DesignT[0] = 1.0\n",
    "DesignT[1] = X\n",
    "Design     = DesignT.T\n",
    "# Define matrix A, vector b and scalar c. Note that theta_0=0.\n",
    "A = numpy.dot(DesignT, Design) + numpy.identity(2)\n",
    "b = numpy.dot(DesignT, Y)\n",
    "c = numpy.dot(Y, Y)\n",
    "# Use a trick to get inverse matrix from more stable Cholesky decomposition.\n",
    "cholesky = cho_factor(A)\n",
    "Ainv     = cho_solve(cholesky, numpy.identity(2))\n",
    "# Compute log-evidence of second model. Drop irrelevant normalisation constants.\n",
    "logEvi1   = -0.5*c + 0.5*numpy.dot(b, numpy.dot(Ainv, b))\n",
    "logEvi1   = logEvi1 - 0.5*math.log(numpy.linalg.det(A)) - 0.5*math.log(detSigma) - 0.5*math.log(detSigma0)\n",
    "evidence1 = math.exp(logEvi1 - 0.5*N*math.log(2.0*numpy.pi))\n",
    "# Print analytic evidence and Bayes factor.\n",
    "print \"P(D|M_0) = \"+str(evidence0)\n",
    "print \"P(D|M_1) = \"+str(evidence1)\n",
    "print \"BF       = \"+str(evidence0/evidence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ideally, you want to run an MCMC and use it to find the best-fit parameters <i>and</i> simultaneously get the Bayesian evidence. Let us write the inverse evidence:\n",
    "\\begin{equation}\n",
    "\\frac{1}{P(D|M)}=\\frac{1}{P(D|M)}\\underbrace{\\int P(\\theta|M)d\\theta}_{=1\\,\\textrm{(prior norm)}}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "=\\frac{1}{P(D|M)}\\int \\underbrace{\\frac{P(D|M)\\,P(\\theta|D,M)}{P(D|\\theta,M)}}_\\textrm{Bayes' theorem}d\\theta\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "=\\int \\frac{P(\\theta|D,M)}{P(D|\\theta,M)}d\\theta\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\frac{1}{P(D|M)}\\approx\\frac{1}{S}\\sum_{s=1}^S\\frac{1}{P(D|\\theta_s,M)}\n",
    "\\qquad\\textrm{where}\\qquad\n",
    "\\theta_s\\sim P(\\theta|D,M)\n",
    "\\end{equation}\n",
    "This is called the <font color='red'>harmonic mean estimator</font> (HME): We draw MCMC samples from the posterior $P(\\theta|D,M)$ which we can use to estimate $\\theta$ but from which can also estimate the <i>inverse</i> evidence by averaging the <i>inverse</i> likelihoods.\n",
    "* Since the HME averages the <i>inverse</i> likelihoods, it is dominated by low-likelihood samples. It is numerically extremely unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Currently, there is no reliable method for running a <i>single</i> MCMC in order to estimate parameters and evidence at the same time.\n",
    "* <font color='red'>Simulated annealing</font> runs multiple MCMC chains in parallel, which exchange samples in a non-trivial manner.\n",
    "* The <font color='red'>cross-validation likelihood</font> runs multiple MCMC chains (one for every cross-validation subset) but without cross-talk.\n",
    "* <font color='red'>Nested sampling</font> is less useful for parameter estimation but gives much better evidence estimates than plain Monte-Carlo sampling.\n",
    "* <font color='red'>Multi-nested sampling</font> is currently the most efficient method to estimate Bayesian evidences (and parameter values) for models with many dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 Consistency of Bayesian evidence\n",
    "* Bayes factors are consistent estimators, especially for nested models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f667d01d6d0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAGcCAYAAAAfyz5tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuUHHWd///nO2AIdybBXRDChDtmRiBBESQJgwKrkoku\nkqigoMLB2+KQ3e8mXslEdI+3n0NAQFDRgIjmoiK4qxilQxCR3ECSqBggQ2QSBToJl3DP+/dHVSed\nSc+ku6u6q7r69Tinz0yqqqve1VPJvPL5fOpT5u6IiIiISPWGJF2AiIiISKNToBIRERGJSIFKRERE\nJCIFKhEREZGIFKhEREREIlKgEhEREYlIgUpEREQkoqYNVGb2YzO738yWmdm9ZvbWpGsSERGRxmTN\nOrGnme3j7k+H3x8P/NbdRyRcloiIiDSgpm2hKoSp0H5AcyZLERERiawhApWZHWRmV5nZPWb2nJlt\nMbNDBtj2YDObZ2YbzWyTmc03s5EDbPtNM3sYmAu8p5bnICIiItnVEIEKOAI4B8gDdzFAa5KZ7Q7c\nCRwFfBD4AHAk8Ltw3Xbc/T/d/XDgPODrZrZrbcoXERGRLGuIQOXuC939QHefCMwbZNOLgVHAu9z9\nNne/DZgULvvoIPu/A2gB3hBb0SIiItI0GiJQVaATuNfdHy0scPc1wO+BdxWWmdkwMxtV9OeTgeHA\nI/UqVERERLIja11cbcDPSyxfSdBlWLA78CMz2wt4FXgWONvdN9W+RBEREcmarAWq4cCGEsvzBF16\nALj7BuAt9SpKREREsi1rgQpKD1i3KDs0M02pICIikiHuHikb9Je1MVQbCFqp+muhdMtV2dy94V8z\nZszIzHGj7rOa91fynnK3LWe7wbZJ6mdai1cS59KM12a528exTVauT12b0faRxL+dO1tfC1kLVCsJ\nxlH1NxpYVedaUqejoyMzx426z2reX8l7yt22nO2S+rnVWxLn2YzXZrnb69rcRtdmtH0k8W9nEj+z\nhnv0jJldCFwPHOruj/Vb1wV8HTjKg7v7CO/mewiY5u5XVHlMb7TPSZpDd3c33d3dSZchUpKuT0kr\nM8Nj7vJrmDFUZlaYyfyNBGOi3mlmTwBPuPtd4brvAJ8EbjWzL4TLvgj0EoQwkUxplhYCaUy6PqWZ\nNEwLlZltofSA84Xu/tai7Q4GeoAzCILXAmBq/9asCo/tM2bMoKOjQ/9AiIiINKhcLkcul2PmzJmx\nt1A1TKBKkrr8REREsqMWXX5ZG5QuIiIiUncKVCIiIiIRKVCJiIiIRKRAJSIiIhKRAlWZuru7yeVy\nSZchIiIiVcrlcjWbG013+ZVBd/mJiIhkh+7yExEREUkhBSoRERGRiBSoRERERCJSoBIRERGJSIGq\nTLrLT0REpLHpLr+E6S4/ERGR7NBdfiIiIiIppEAlIiIiEpEClYiIiEhEClQiIiIiESlQiYiIiESk\nQCUiIiISkQJVmTQPlYiISGPTPFQJ0zxUIiIi2aF5qERERERSSIFKREREJCIFKhEREZGIFKhERERE\nIlKgEhEREYlIgUpEREQkIgUqERERkYgUqMqkiT1FREQamyb2TJgm9hQREckOTewpIiIikkIKVCIi\nIiIRKVCJiIiIRKRAJSIiIhKRApWIiIhIRApUIiIiIhEpUImIiIhEpEAlIiIiEpECVZk0U7qIiEhj\n00zpCdNM6SIiItmhmdJFREREUkiBSkRERCQiBSoRERGRiBSoRERERCJSoBIRERGJSIFKREREJCIF\nKhEREZGIFKhEREREIlKgEhEREYlIgUpEREQkIgUqERERkYgUqEREREQiUqAqU3d3N7lcLukyRERE\npEq5XI7u7u6a7NvcvSY7zhIzc31OIiIi2WBmuLvFuU+1UImIiIhEpEAlIiIiEpEClYiIiEhEClQi\nIiIiESlQiYiIiESkQCUiIiISkQKViIiISEQKVCIiIiIRKVCJiIiIRKRAJSIiIhKRApWIiIhIRApU\nIiIiIhEpUImIiIhEpEAlIiIiEpEClYiIiEhEClQiIiIiESlQiYiIiESkQCUiIiIS0a5Rd2BmRwCj\ngH2BocBzwN+Bv7n7M1H3nxbd3d10dHTQ0dGRdCkiIiJShVwuRy6Xq8m+zd0re4PZPsD7gH8HxgF7\nAFZi0y3ASuA24Ifu/pdopSbHzLzSz0lERETSycxw91LZpWpld/mZ2TAzmwk8AlxIEJY+AIwFWoG9\ngd2A1wHtwJnAHOCNwB/N7DYzOyrO4kVERETKtWzZMs4888ya7LusFiozOx74PvAH4Bvu/khFBzHb\nC/hE+Pqau19TRa2JUQuViIhI4+vr62PZsmV0dnbG3kK100BlZicD/wNc4O6PRTqY2TBgFvCUu382\nyr7qSYFKRESkMfT19XH77bdz0UUXMWRI6Y64pLr83gm8PWqYAnD3F9z9o8DDZvb6qPsTERER6evr\n46qrrmLChAm0tbVx99138+yzz9a1hooHpTcjtVCJiIik03/8x39w880309nZyZQpUzjjjDPYbbfd\nBn1PLVqoFKjKoEAlIiKSTmvWrOHAAw/caYgqpkCVEAUqERGRZPT19TF//nwALrnkklj2mei0CTtj\nZuea2UIzW2lm15rZ/kXrLjSzr4bTLoiIiIgMqDAmavz48bS1tbFkyRLa2tqSLmtQsbRQmdlFwFXA\nfcATwHHAPsBZ7r4k3OYdwO3uvkvkA9aZWqhERETq46mnnuLoo4/mrLPOYvLkyWWNiapULVqoIj96\nJvQBYLS7P1pYYGaTgO+b2fnuvpxg5nQRERGRAY0YMYL169ez664DR5QwENWxqp2Lq8vvj8VhCsDd\nfwGcCkwzs+NiOo6IiIg0sOIpDgZ6rt5gYSqt4gpUL5jZrmZ2oJm9qbDQ3fPAeQTP/XtzTMcSERGR\nBrJ+/fqtIaq9vZ0lS5Ywbdo0Tj755KRLi01cY6gOAD4DvAU42N0PLLHNRcDV7h5vR2gdaAyViIhI\n9W666SYWLFgQ25ioqF1+iU6bYGY5d+/YyTZHAJvdvW+A9Ue5+0MVV5kwBSoREZGde/bZZ9lrr71q\nfpw0BqpKuvxet7MN3H31QGEqXN9wYUpEREQGVjzFwZgxY1I3WLxeKglUh5nZZ8zs+JpVIyIiIg3h\n2muv3W6eqOnTp7NixQrMYm342UE+nwdgw4YNNT1OpSoJVEOALwFLzewpM/upmXXt7A4+M3t7pApF\nREQkdZ599lmmT5/O+vXrmT17NhMnTox9vqj+enp6GDt2LABjxoyhp6enpserRCVjqC4DTgQeIZgO\noR0wwIENwMLwdae7P1j0vuXuPibmuutKY6hERKQZ9fX18eKLL3LooYcmXQr5fJ6xY8fS29u7dVlr\nayvLli1j+PDhFe0r0TFU7v5F4NPAy8B7gdcC5wBXA48D7wauAO43syfMbJ6ZXQocEmfBIiIiUjvF\n80S1t7fz29/+NumSAFi5ciVr167dbtnatWtZtWpVQhVtr+JpEyzoHP0osAdwpbu/Ei4fTtBydRr9\nWrAa8XEzxdRCJSIiWfeXv/yFiy++mBUrVtDZ2Vmzx75Ua8OGDYwZM2aHFqrly5fT0tJS0b4SnTah\nRDEjgS7gp+5+T4n1w4G3Aze4+7BIVSZMgUpERLJu06ZNLFq0KFUhqr+enh5mzZpFb28vra2tdHV1\nMXXq1Ir3k6pAtXUHZu8FjgG+6e7PlFj/F3c/JtJBEqZAJSIiWdDX18dPf/pTLrroIoYNa8y2jnw+\nz4gRI8jn8xW3TBUkPQ9VSe7+E+Aq4DNm9q4SmyyNegwRERGpTvE8UW1tbSxevJhNmzYlXVbVCgPQ\nqw1TtRLLo2e27szsdOBMgtaq9bHtuAbMbD/gJuBI4HngH8An3f3hEtuqhUpERBrO5z73Oa655hom\nTZqUujFRUaRxpvRYAxWAme0O/BfQ5+43xLrzGJnZvsAJ7v678M+XAGe7+2kltlWgEhGRhtPX18eI\nESMyEaKKZTpQmdluwGHA4cARwNkEc1Rd7O5/jeUgNWRmJwBz3f2wEusUqEREJHX6+vqYP38+Gzdu\n5Atf+MKg20YNIWmSxkC1a4UFtBAEplKvAwmmSaDo67PAt4AzohZqZgcRzIN1AnAcsDswyt0fK7Ht\nwQRzYp0e1rIAuNTd1/bftsilwM+j1ikiIlJLhRA1Z86crVMcnHfeeUmX1fQqmSn9n8CIwh+LVv0D\neLjo9Ujhe3f/Z2yFmp0K/JhgkPsuBGO1Du0fqMIuxz8RjIv6XLj4ywQB7Fh3f77EvmcQhL7T3f2F\nEuvVQiUiIol78cUXOfzww3nb295W8ZgotVDt8P7EWqj2BxYD84CHCMOTu2+Os6CBuPtCglYwzOxC\ngkBVysXAKOAod3803P5B4G8EE5JeUbyxmX2eYL6sM0qFKRERkbTYbbfdeOyxxxgyJPJN+hKzSn4i\nzxI8q+9twPkEgeYY28ljpc3sgOrLq0oncG8hTAG4+xrg98B20zqEzyc8CzjT3Z+tZ5EiIiL9FU9x\nMHfu3JLbKEylUyU/lUfdfZq7v50gUK0EJgP/Gz63b6qZHV/ifQvjKLQCbcCKEstXAqMLfzCz0UA3\nQTfmQjNbbmb31aVCERGR0D/+8Y/t5olasmQJ06dPZ9KkSbEdI5/PA8HjW6Q2Kuny+3rhG3d/Dvh1\n+MLM9gTGAe81s/8BniNoEXoKqPcjqocDpa6YPLB1FjB3X0UME5uKiIhEsXTp0q0hqhbzRBUe1wIw\nZsyYqh/XIoOLfR4q2C5gTQM64n44cjiG6npKD0p/EfiGu3+u3/IvAdPcfWgVx/MZM2Zs/XNHRwcd\nHR3VlC4iIk1q48aN7LfffnU9Zj6fZ+zYsTs8UHjZsmVbZxxvRJUOSs/lcuRyua1/njlzZnrnoSq5\nc7O9gXXuvlfM+x0sUK0HfubuH++3/GrgHHf/1yqOp7v8RESkYsVTHKxevZre3l6GDq34//VVW7Ro\nER0dHWzZsmXrsiFDhrBw4ULGjRtXtzrilsa7/Gra5RU+LPmhWh6jhJUE46j6Gw2sqnMtIiLShG64\n4QbGjx9Pe3v71u68NWvW1DVMAbS3tzNy5Mjtlo0cOZK2tlK/JiWKeowhOrkOxyj2C+AkMxtVWBB+\nfwpwa51rERGRJvTKK68wffp01q1bx+zZs5k4cWIij39paWmhq6uL1tZWIOju6+rqSt2DhbOgpl1+\ncTOz94Tfnk4wp9QngCeAJ9z9rnCbPYD7CSb2LMzD/0VgT+C4aubNUpefiIj019fXx8aNGxk9evTO\nN05YPp9nxIgR5PP5TISppuvyq4G5wByCyTsduDr8c3dhgzAwvZWgq/FG4CaCSUjfFmUS0u7u7u0G\ntImISPMpzBM1YcIE2tra+NWvfpV0SWUpDEDPQpiKIpfL0d3dXZN977SFysymAnvHfNyn3f2KnW+W\nDmqhEhFpbmvXruW8887jwQcfpLOzkylTptRkioNa0qNndnh/fe/yM7OziT9QPePuP415nzWjQCUi\n0txefvllfv3rXzdciCqmQLXD+xtn2oSsUKASEcm+whQH73//+9l///2TLid2ClQ7vL+px1CJiIjE\npvjZeYUpDp577rmky5IGVMmjZwAIH4Z8GnAq8FqCx8usBP7P3TfFW156dHd3a4Z0EZEM+drXvsZX\nvvIVOjs7a/bYF0mX/jOmx6miLj8zawN+CBwLFJrKCjt4BZgNXO7ua+MsMmnq8hMRyZ4nn3ySvffe\ne6chKitdZVk5D0hnl1/ZgcrMDgKWAEOB7wKrgWHAYcCJ4WsX4BngI+4+P85Ck6RAJSLSeApjoh55\n5BF6enqq3k9WgkhWzgPSGagq6fL7LMF8Tu929yf7rzSz4cAFwKeAOWb2CXe/Lp4yRUREdq4QoubO\nnbt1ioP3vve9SZclTaCSFqqHgXe4+6DP5jOzocBlwDRgorvfEbnKhKmFSkQk/dydtrY23vjGN8Y6\nT1RWWnaych6QzhaqSgLVQ+5+VNk7NvsY8GlgdJQZytNAgUpEJF3cneAeqfKWVytLj2xRoNrh/YlN\nm1DRHXzu/m1gGfDBiioSEREpoXiKg2uuuabkNnGGqZ6eHsaOHQvAmDFjIo3DkuyrJFBVEwW/DLyv\niveljp7lJyJSf08++eTWENXW1saSJUuYPn06F110UU2Pm8/nmTVrFr29vQD09vYya9Ys8vl8TY8r\ntZXos/y2bmi22N3fVPEBzB509zdUXFmKqMtPRCQZf/zjH7nmmmuYPHlyXeeJWrRoER0dHWzZsmXr\nsiFDhrBw4ULGjRtXlxripi6/Hd6f2BiqPPAe4G53f7nsA5gtdfcTqqwvFRSoRERq68knn0zV4142\nbNjAmDFjtrZQAbS2trJ8+fKGHUulQLXD+xMbQ7UfsADYaGYLzOzzZjbOzF6zk/e9Wn15IiKSVYUx\nURMmTODoo49m48aNSZe0VUtLC11dXbS2tgJBmOrq6mrYMCW1V0kL1WZgHjABOCRc7MALwB+AXPj6\nY3ELlpnd5+4nxldy/amFSkQkPjfffDPXXXcdK1asoLOzs+7deZXQXX7plMYWqkoC1daxUGZ2CMHz\n/ArP9GsNNysOWHcCdwHfcfdj4iy63hSoRETi85Of/IQ999wztSGqv6wEkaycBzR+oJrq7iXvGTWz\nUUAH2wJWcQsW7r5LxDoTpUAlIlKZvr4+1q1bxwknNPQQWiA7QSQr5wHpDFRlj6EaKEyF69a4+w/c\n/QJ3HwUcDlwIZOZ5fpo2QURkcMXzRLW1tfHLX/4y6ZJEtpOKaROqPoDZmjBkNSy1UImIDGzDhg1M\nmjSJFStWMGnSpFSPiapGVlp2snIekM4WqnoEqmXuPramB6kxBSoRkYG5O3fccQcdHR2ZCVHFshJE\nsnIe0LyB6kB3X1fTg9SYApWINLu+vj7mz5/PWWedxWGHHZZ0OXWVlSCSlfOAdAaqnY6hMrPhZrZH\ntQcYKEyFdwqKiEhKPf7441x55ZWMHz+e9vZ2Fi9ezMsvlz2vc6zP1RNJu3IGpe8K3GBm/xLXQc3s\nHOAzce1PRETidf311/OGN7yBpUuXMn36dNatW8eNN97I0UcfnXRpIqlUVpefmR0OzAauB26qtv/L\nzA4CPg/sCXzE3V+pZj/1pi4/EWk2mzZtYtiwYZHGRGWli0nnkT4N2eUH4O4PA+8kmCX9r2b2WTM7\n3spozzWzvc3s7Wb2fWAZ8IC7n98oYUpEJIsKUxycf/75Jdfvu+++kcJUPp8HgjsARZpBJfNQPe3u\nFwHvA9qBe4BNZvY7M7vRzK40s8vN7Ktm9h0zm2dmS4E8cAPwONDu7t+uxYmIiMjg+s8TtWTJEqZM\nmRJ7q0VPTw9jxwY3d48ZM4aengGnMRSpShpb2qq+y8/M9gbOAE4GXg8cBOxF8DDkjcAa4E8Ej5/5\nfSP3mZmZz5gxg46ODjo6OpIuR0SkKhMmTODQQw+t6TxR+XyesWPH0tvbu3VZa2sry5YtY/jw4bEf\nrx6y0lWWlfOIIpfLkcvlmDlzZrLTJpjZUGAyMBxY6O5/irOYtNIYKhFpJO5e8g67gZbHadGiRXR0\ndLBly5aty4YMGcLChQsZN25cTY9dK1kJIlk5jzgk+uiZsEXqXuBG4ApgmZl9Jc5iRESkOsXdeTNn\nziy5TT2mMWhvb2fkyJHbLRs5ciRtbW01P7ZIksoOVMB/A0cAtwILgM3Af5vZp2pRmIiIDC6fz+8w\nJmr69Ol85jPJzUrT0tJCV1cXra2tQNDd19XVRUtLS2I1SUCtU7VVdpefma0Cutz9N+Gf9wCmhq8j\n3T2zt3Koy09E0mj16tVcfvnlqXx2Xj6fZ8SIEeTz+YYPU+oqy55EHz1jZr3u3lpi+Qzgn+5+bZyF\npYkClYgkad26dRxwwAENN/N4VoJIVs5Dtkl0DBXw1ADLZwGnxVCLiIiECmOiJkyYwOjRo7e7a05E\n0qeSQFVyIk533xhTLSIiTW/evHlMmDCBtrY2Fi9ezLRp01i/fj2jRo1KujQRGcSuFWw7WNOYZj0X\nEYnBHnvswbRp01I3JkpEBlfJGKo8cDawyN1f7bfuFnd/fw3qSwWNoRKROPX19fHII4807LxM5dLY\nI0mrpMdQ7Qf8FthgZreZ2VQzaw/XDfg3xsyOi1KgiEgWFM8T1d7ezm233ZZ0SSISo0q6/F4A5hE8\nIPms8OVm9iTwkpl9GrgbuM/dXyp63w3ACTHVm5ju7m49ekZEKvbiiy9y5pln8uCDD9LZ2cn06dPV\nnSeSkMKjZ2qhki6/P7n7seH3hxDc2XcacCpQmE7BgZeAJcAigpnVr3f3A2Kuu67U5SciUdx11128\n+c1vLitEZambLEvnItmS9DxUl7r7FQOsGwV0sC1gHRKucgB33yVinYlSoBKRwfT19TF//nzGjx/P\n8ccfH2lfWQohWToXyZZEx1ANFKbCdWvc/QfufoG7jwIOBy4E5kcvUUQkfYrniSpMcTBkSCXDUkUk\nS8puoar6AGZrwpDVsNRCJSLF5s6dy8UXX0xnZydTpkyJdUxUllp1snQuki2JdvlVfQCzpe7e0IPS\nFahEpNjmzZvZZZddajKwPEshJEvnItmS9LQJ1TqrDscQEYlNoTtv0qRJvPrqqzus32OPPXSXnohs\np+aByt3X1/oYIiJR9Z8nasmSJVx88cVJlyUiDWKnXX5mNhH4N+BH7v6HulSVMuryE8m+c845hz33\n3JPJkycnOk9UlrrJsnQuki2JjKEys92AfwfOBY4iuHPvR+6+Ms5C0kyBSiQ7tmzZkuq78bIUQrJ0\nLpItiQ9KN7PhwGSCcLUPcAtwi7uvjbOotFGgEmlshXmi5s6dy7HHHsu3vvWtpEsaUJZCSJbORbIl\n8UDVr5iDgfeHr2cIwtUcd8/HV146KFCJNJ6nn36a2bNnM3fu3K2PfYl7ioNayFIIydK5SLakKlBt\ntxOz1wPnAecAq4EfAT93982Rd54CClQijeepp55i6tSpDRGiCvL5PCNGjCCfz9PS0pJ0OZEpUEla\npTZQbbdDs5MIwtVZwB8IwtWv3H3He48bhAKVSHr19fWx//77M3To0KRLiaSnp4dZs2bR29tLa2sr\nXV1dTJ06NemyIlGgkrRqiHmo3P1ed78EOAK4EZgC/M3MrjWz8XEfr166u7tr9oRqEalM8RQHbW1t\n/PnPf066pEjy+fzWMAXQ29vLrFmzyOczN4JCJFG5XI7u7u6a7LvmM6UDmNkwoJOg5Wo08DPgJndf\nUfODx0AtVCLpcPvtt/PVr36VFStWMGnSpMSnOIjLokWL6OjoYMuWLVuXDRkyhIULFzJu3LgEK4tG\nLVSSVg3R5bfTA5rtRzDWapy7f6iuB6+SApVIOtx9991s3LgxEyGq2IYNGxgzZszWFiqA1tZWli9f\n3tBjqRSoJK0aostvZ9x9o7t/t1HClIjUV19fH7/+9a9Lrhs3bhwTJ04sGabMYv23sa5aWlro6uqi\ntbUVYOsYqkYOUyLNpu4tVI1ILVQitVU8T9SKFSs499xzK54rKgutIbrLT6Q+UtnlZ2ZHAKOAfYGh\nwHPA34G/ufszUQtMAwUqkdpwd/7t3/6NJUuW0NnZGWlMVFZ+eWflPCBb5yLZkopAZWb7AO8jeBzN\nOGAPoFRRW4CVwG3AD939L9FKTY4ClUjtLF68mGOPPTbymKis/PLOynlAts5FsiXRQBXeqfcZ4JPA\nw8Ci8LUGyIevl4ARwHDgAOBkYHz49S7gv9z9oThPoB4UqESqV+jOe8Mb3kBHR0fNjpOVX95ZOQ/I\n1rlIttQiUO1a5oGPB75PMFHnie7+yCCbrw9fq4Dfhe/fC/gEcIeZfc3dr4lUtYikWiFEzZkzZ+sU\nByeffHLSZYmI1MxOW6jM7GTgf4AL3P2xSAcLWrlmAU+5+2ej7Kue1EIlUr4FCxYwefLkus4TlaXB\n3Flq1cnSuUi2JNLlZ2aXA19y9xdjO6jZhcA97t4Q0xsrUImU76WXXsLd6zZPVNYe2ZKlEJKlc5Fs\nScWg9GakQCWyTaE779Zbb+XnP/85e+21V2K15PN5xo4du8OEmMuWLWP48OGJ1RVFlkJIls5FsiUT\nE3uKSOPp/+y8xYsXc+mllyY+W/nKlStZu3btdsvWrl3LqlWrEqpIRJqVWqjKoBYqaXYf//jH2bx5\nc+qenZfFR7ZkqVUnS+ci2dLwXX5mdpa7/7JuB4yJApU0i1deeYVddy3r5t/U0Biq9MrSuUi2ZCFQ\nfdfdL6rbAWOiQCVZVjzFwcEHH8wtt9ySdEkV011+6ZSlc5FsSW2gMrOrgd3L2PTd7t5wI0UVqCRr\nNm/ezPe+973t5olKW3depbLyyzsr5wHZOhfJlsQm9izDPUAXwaNmBqO/WSIpsMsuu/CnP/2J6dOn\nN3SIEhFJi9i6/MzsG+7+/3ayzffc/cJYDlhHaqGSRtXX18c+++yT6NQG9ZKV1pCsnAdk61wkW9I+\nbcJ9ZWzzsxiPJyIl9J/iYNmyZUmXJCKSeWUHKjPLDbbe3efsbB/ufnu5x0ub7u5ucrlc0mWIDOi3\nv/3t1hC1ZMkSpk+fzvr165kwYULSpUmTUuuUpE0ul6O7u7sm+y67y8/MHnL3o2pSRcqpy08awQMP\nPMDatWubdkxUVrqXsnIeImmW6F1+ZvYK8AXg/9z9/jiLSDsFKkmLvr4+7r33Xs4+++ykS0mdrASR\nrJyHSJolPYZqCPAlYKmZPWVmPzWzLjM7brA3mdnbI1Uo0uQKY6ImTJhAW1sbt99+u37hioikTCUt\nVJcBJwKPAKcC7YARTIWwAVgYvu509weL3rfc3cfEXHddqYVKknL22Wdz55130tnZyZQpU5q2O68c\nWWnZycp5iKRZ4hN7mlk78GHgO8A/gY7w1T9g5QnC1d3AF9x9RJxF15sClSTlwQcf5KijjlKIKkNW\ngkhWzkMkzRIPVGERBnwU2AO40t1fCZcPJwhWp9EvYLn7LnEWXW8KVFIrhce+tLa2MmnSpKTLaWhZ\nCSJZOQ+RNEt6DBUQpCN3/zYwF/iKmb0lXJ5395+5+6fc/TjgtcAHgJfjLFik0RXPE9Xe3s6SJUt4\n7WtfW9VM7IS6AAAd9ElEQVS+gv/fiIhI0iLPlG5m7wWOAb7p7s+UWP8Xdz8m0kESphYqicuyZcs4\n/fTT6ezsjOXZeWrN2CYrn0VWzkMkzVLR5VdyJ0F33/8D/ujut/Zbd7O7nxf5IAlSoJK4bNmyhZdf\nfjm2MVH65btNVj6LrJyHSJqlosuvlLC777PAc2b2NTM7oGhdQ4cpkUoUT3Hw+OOP77B+yJAhGmAu\nIpJBcT7LD3dfAMwALjKzj8S5b5G06j9P1OLFi5k2bVrV46JERKTxxNLlB2BmuwGHAYcDRwBnE0yh\ncLG7/zWWgyREXX4ymMsuu4w1a9YkMk+Uuoe2ycpnkZXzEEmzxMdQmVkLQWAq9TqQYJoEir4+SzCu\n6oy4Ck6CApUAvPTSSwwdOjTpMrajX77bZOWzyMp5iKRZLQLVrhUc/J9AYYLO4iL+ATwM/C78+kj4\n9WF3/2dMdYokojBP1Jw5cxg2bBi/+c1vki5JRERSqJJHz2wBFgPzgIcIw5O7b65deemgFqrm8tJL\nL3HdddcxZ84cVqxYwaRJk2KZ4qAW1JqxTVY+i6ych0iaJdpCRdB9txB4G3AS8HsgFz6rb8C//WZ2\ngLuvj1amSP285jWvYfXq1UyfPj2VIUpERNKnkhaqB8IZ0DGzPYFxBM/xOx54jiBg3enu9/d731/d\n/eg4i643tVBlU19fH7vtthsjRjTuoybVmrFNVj6LrJyHSJolOijdzD7g7j8cYF1xwDqObQHrKeB7\n7p6ukbwVUqDKjsKYqLlz57JixQpuvPFGJk6cmHRZVdMv322y8llk5TxE0izxu/zK3um2gDUN6NDD\nkSVp99xzD5/+9KdZsWJFbI99SQP98t0mK59FVs5DJM0aJlBt3bnZ3sA6d9+rZgepAwWqxvfwww/z\n5z//ORMhqiCfzzNixAjy+TwtLS1Jl5O4rASRrJyHSJql9tEzAwkflvxQLY8hUtDX18eNN95Yct3h\nhx/OxIkTMxOmenp6GDt2LABjxoyhp6cn4YqSpxAiIkmqaQsVBDOou/uLNT1IjamFKr2K54kqTHFw\n/fXXZyY4lZLP5xk7diy9vb1bl7W2trJs2TKGDx+eYGUSB7VQidRew7VQATR6mJL0+tCHPkRbWxtL\nlixh+vTprF+/ntmzZ5cVpsxi/XtUVytXrmTt2rXbLVu7di2rVq1KqCIREal5C1VamdnngQ8ARwL/\n7u6/GGRbtVCl0EMPPURra2tVrVGN3AqwYcMGxowZs0ML1fLlyzWWKgMa+doUaRSJTOxpZlOBveM8\nKPC0u18R8z4rdQfwQ+CGhOuQARS68/bZZx8uuOCCHdYfddRRCVSVvJaWFrq6upg1axa9vb20trbS\n1dWlMCUikqCdtlCZ2dnEH6iecfefxrzPqpjZnUCPWqjSof88UZ2dnXzkIx/h1FNPjfU4WWgF0F1+\n2ZSFa1Mk7RJpoUpD8DGzg4BPAycQTBy6OzDK3R8rse3BwBXA6QQPcV4AXOrua/tvK+nS29vLmDFj\n6OzsZNq0aZma4qAWCgPQFaZERJJXybP8knQEcA6wFLgLOLPURma2O3An8DzwwXDxl4Hfmdmx7v58\nHWqVKrW2trJ+/XqGDm3oifVFRKQJVXyXnwXeamYzzewaM7vczN5nZvvWokAAd1/o7ge6+0Rg3iCb\nXgyMAt7l7re5+23ApHDZR2tVn5Snr6+Pq666ivHjx/PAAw+U3EZhSkREGlFFLVRm1kYwkPtYgu40\ngEJn/ytmNhu4PMHutU7gXnd/tLDA3deY2e+BdxF0BUodrVu3jnnz5m03T9T06dM55phjki5NJJU0\nfkqkMZUdqMJxTAuAocA3gNXAMOAw4MTwdRHwXjP7iLvPj7/cnWoDfl5i+UqCLsOtzGwGQb37A981\nsxeAk9y9r+ZVNpF58+ZtnSdKY6JERCSrKmmh+izwMPBud3+y/0ozGw5cAHwKmGNmn3D36+Ips2zD\ngQ0llueB7UbuuvtMYGY9imoGzz//PLvvvvsOyy+55JIEqhEREamvSgLV24F3lApTAO6eB3rM7Grg\nMuAqM3vU3e+Ioc5KlGovj3xrZHd399bvOzo66OjoiLrLhlf82JfNmzezdOnSpEsSERHZQS6XI5fL\n1fQYZc+UbmYPuXvZMyma2ccIpjoY7e6bq6yv1H4vBK4HDu0/bYKZrQd+5u4f77f8auAcd//XKo+p\neahC7s63vvWt7cZETZ48ueG687Iy109WzkNEpJ4SmYeqyKZKduzu3zazMwmmL6hX199KgnFU/Y0G\n9KCzGJgZTz75pMZEiYiIFKlk2oRq/hv8ZeB9VbyvWr8ATjKzUYUF4fenALfWsY6G19fXR19f6fH5\nM2fOZOLEiQpTIiIioUoCVcVNY+6+lOAuusjM7D1m9h7gjWEt7wyXTSja7DvAGuBWM5tkZpMI7vrr\nJegmlEEUzxPV1tZW8/7mpOTzeSB4yLCIiEgcKglUh5vZaWb2mgqP8VKF2w9kLjCHYPJOB64O/9xd\n2CAcq/VW4CHgRuAmgjsT3xZ1HFd3d3dmA8b999+/NUQVpjhYv3495557btKlxa6np4exY8cCMGbM\nGHp6ehKuSERE6iWXy213k1mcKhmUvoUgyLwA/AHIha8/uvvLg7zvPnc/MXKlCcr6oPT169ezZMmS\nzI+JyufzjB07lt7e3q3LWltbWbZs2dbn4jUaDUoXEalcLQalV9JC9QJwM/AEQSvQF4GFwEYzW2Bm\nnzezcVW0YEkd9PX1cd1117Fly5Yd1h1wwAFNMSZq5cqVrF27/ST+a9euZdUq3a8gIiLRVBKoHnb3\n8919FMGz8T5M0KX2T0oHrM+Z2Xhgn3hLlnIVj4lqb2/nnnvu4emnn066rMS0t7czcuTI7ZaNHDmS\ntrZSN4aKiIiUr5JAdUPhG3d/zN1nu/uH3P1QgsfPfITgOX+FFqzLCboEj4yvXClXV1cX7e3tW8dE\nrVu3jtmzZ7PffvslXVpiWlpa6OrqorW1FQi6+7q6umhpadnJO0VERAZX9hiqinZqdijQAbwDeI+7\n7xL7QeqoEcdQ9fb2csABB2S+G68a+XyeESNGkM/nGz5MaQyViEjlkp7Ys2zu/ijwKPB9M1tTi2PU\nW3d3d6oeOVN47Murr77KpZdeusP6QiuM7KgwAL3Rw5SIiFSmlo+gqUkL1XYHMFvm7mNrepAaS0sL\nVSFEzZ07lwcffJDOzk7OP/98Tj/99KRLazhZadnJynmIiNRTLVqo6hGoDnT3dTU9SI2lIVBt3LiR\nI488kne84x1MmTIl81Mc1FpWgkhWzkNEpJ4SCVRmNhx4Ic4HHIf7PaT/w43TKg2BCuCVV15h111r\n0kvbdLISRLJyHiIi9ZTUPFS7AjeY2b/EdVAzOwf4TFz7y4LCFAcTJkxgwYIFJbdRmBIREUmnsrr8\nzOxwYDbB8/Buqra5xswOAj4P7Al8xN1fqWY/9VarFqr169czd+5c5syZw8qVK+ns7GTy5MnqzquD\nrLTsZOU8RETqKdExVGa2D/BNYALwA+B/gQd2ljTMbG/gFOC9wDuBGe7+7Qg1112tAtUtt9zCr371\nK4WoBGQliGTlPERE6ikVg9LNbAzw38C7gVeAJcDfgY3AJmAoMBxoAQ4FjiWY7PMGYJa7PxFX8fVi\nZj5jxoyqp0145pln2HvvveMvTKqWlSCSlfMQEamHwrQJM2fOTDZQmdlQYDJBYHoAGAG8BXg9cBCw\nF/AqQbhaA/wJuAv4fSpGdVepmhaq4ikO/v73v7N69WqGDKlkYnqppawEkaych4hIPSXd5bc3wbP6\njgsXOfANd/90nAWlUSWB6rrrruPmm2/eOk+UpjhIp6wEkaych4hIPSU9U/p/A0cAtxIMKj8Z+G8z\n63P3K+MsqpE999xzTJs2TSFKRESkiVTSQrUK6HL334R/3gOYGr6OdPcNNasyYf1bqPr6+nj++ec5\n/PDDE6xKoshKy05WzkNEpJ6SmoeqYM9CmAJw983u/mXgKuB9cRaVRoV5osaPH09bWxu/+c1vdv4m\nkRpTmBIRSYdKWqhKPpPPzPYDrnf3KXEXlxZm5vvttx+TJk3SFAcZoZYdEZHmlfQYqpKTcLr7RrNY\na0qlT37yk5x++ulVTZsgIiIiyStMm1ALlbRQLXb3Nw2w7kfufm6slaVIWp7lJ/FRC5WISPNKegzV\n4WbWYWa7lFiX/SYqERERkQFUEqj2A34LbDCz28xsqpm1h+sG/K++mR030DoRERGRLKiky28zMI/g\nWX6HhIsdeBJ4CbgauBu4z91fKnrfUnc/Ic6i601dftmjLj8RkeaV9Ezpf3L3Y8PvDwFOC1+nAq3h\nZk4QrpYAi4B7Ce4APCDOoutNgSp7FKhERJpX0oHqUne/YoB1o4AOtgWs4hYs3L3UuKuGoUCVPQpU\nIiLNK9FAVdFOzQ4lCFjvAN6jQCVpo0AlItK8GiZQbXcAszXuPqqmB6kxBarsUaASEWleSU+bUK2n\n6nCMmuvu7q7ZZGAiIiJSe7lcju7u7prsux4tVAe4+/qaHqTG1EKVPWqhEhFpXg3Z5ZcFClTZo0Al\nItK8GrXLT0RERCTTFKhEREREIlKgEhEREYlIgUpEREQkIgUqaUoakC4iInFSoBIRERGJSIFKRERE\nJCIFKhEREZGIFKjKpEfPiIiINLaGfvRMFmimdBERkezQTOkiIiIiKaRAJSIiIhKRApWIiIhIRApU\nIiIiIhEpUImIiIhEpEAlIiIiEpEClYiIiEhEClQiIiIiESlQiYiIiESkQCUiIiISkQKViIiISEQK\nVCIiIiIRKVCVqbu7m1wul3QZIiIiUqVcLkd3d3dN9m3uXpMdZ4mZuT4nERGRbDAz3N3i3KdaqERE\nREQiUqASERERiUiBSkRERCQiBSoRERGRiBSoRERERCJSoBIRERGJSIFKREREJCIFKhEREZGIFKhE\nREREIlKgEhEREYlIgUpEREQkIgUqERERkYgUqEREREQiUqASERERiUiBSkRERCQiBSoRERGRiBSo\nRERERCJSoCpTd3c3uVwu6TJERESkSrlcju7u7prs29y9JjvOEjNzfU4iIiLZYGa4u8W5T7VQiYiI\niESkQCUiIiISkQKViIiISEQKVCIiIiIRKVCJiIiIRKRAJSIiIhKRApWIiIhIRApUIiIiIhEpUImI\niIhEpEAlIiIiEpEClYiIiEhEClQiIiIiESlQiYiIiESkQCUiIiISkQKViIiISEQKVCIiIiIRKVCJ\niIiIRKRAJSIiIhKRApWIiIhIRApUIiIiIhEpUImIiIhEpEAlIiIiEpEClYiIiEhETRuozOwwM1tk\nZn81s6VmdkLSNYmIiEhjatpABXwb+L67Hw1MB25OuB4RERFpUObuSddQd2a2P/AwMNzdXw2X/QU4\n192Xldjem/FzEhERySIzw90tzn02RAuVmR1kZleZ2T1m9pyZbTGzQwbY9mAzm2dmG81sk5nNN7OR\n/TY7BFhXCFOh3nC5iIiISEUaIlABRwDnAHngLqBkc5GZ7Q7cCRwFfBD4AHAk8LtwXbH++4g1qYqI\niEjzaIhA5e4L3f1Ad58IzBtk04uBUcC73P02d78NmBQu+2jRdo8BrzOzXYqWtYbLRRpGLpdLugSR\nAen6lGbSEIGqAp3Ave7+aGGBu68Bfg+8q2jZk8B9wIcBzOyMcPkO46dE0ky/sCTNdH1KM8laoGoD\nVpRYvhIY3W/Zx4EPm9lfga8C59a4tsQl9Y9bLY4bdZ/VvL+S95S7bTnbNcsvpSTOsxmvzXK317W5\nja7NaPtI4t/OJH5mWQtUw4ENJZbngZbiBe6+2t1Pcfej3X2suy+tS4UJUqCK9n4FqtrSL63q369A\nVVu6NqPto1kCVcNNm2BmFwLXA4e6+2P91r0IfMPdP9dv+ZeAae4+tMpjNtaHJCIiIoOKe9qEXePc\nWQpsIGil6q+F0i1XZYn7QxcREZFsyVqX30qCcVT9jQZW1bkWERERaRJZC1S/AE4ys1GFBeH3pwC3\nJlKRiIiIZF7DjKEys/eE355OMKfUJ4AngCfc/a5wmz2A+4HngS+E238R2BM4zt0317VoERERaQqN\nFKi2UHqG9IXu/tai7Q4GeoAzCGY/XwBM7T+APebaDgNmA/8CPAtc3Ax3DUpjMLPPs+2pAf/u7r9I\nuCQRzGw/4CaC6/J54B/AJ9394UQLEwHM7MfAMcAW4CXgs+7+u0Hf0yiBKs3M7A7gx+5+g5mdDnzL\n3Y9Jui4RADM7EfgncANwhQKVpIGZ7QucUPglZWaXAGe7+2nJViYCZraPuz8dfn888Ft3HzHYe7I2\nhqruzGx/4M0ELVS4+4Jw+dgk6xIpcPf7wicG6G5VSQ1339Tvf/z3EDwCTCRxhTAV2o8BniFcrOkC\nlZkdZGZXmdk9ZvacmW0xs0MG2PZgM5tnZhvNbJOZzTezkf02OwRY5+6vFi3rDZeLVKQG16dILOpw\nbV4K/Dz+yiXranVtmtk3zexhYC7wnlLbFGu6QAUcAZxDMHv6XQyQOs1sd+BO4Cjgg2wbg/K7cF2x\n/vtQS4BUqxbXp0gcanZtmtkM4FDgs/GXLU2gJtemu/+nux8OnAd83cwGnbszaxN77pS7LwQOhK2z\nrp85wKYXA6OAowoPWzazB4G/EdxleEW43WPA68xsl6JWqtZwuUhFanB9isSiVtdmeNPE24Ez3P2F\nmhQvmVbrfzfd/Q4zuxp4A7B8oDqasYWqXJ3AvYUPHSAch/J74F1Fy54E7gM+DGBmZ4TLl9WzWGk6\nZV2fIgko+9o0s8uAs4Az3f3ZehYpTamsa9PMhvWbz/JkgqewPDLYzhWoBtYGrCixfCXBzOvFPg58\n2Mz+CnwVOLfGtYmUfX2a2QwzWwucBHzXzB4zs9fVoUZpTmVdm2Y2GugGRgALzWy5md1XlwqlWZX7\n7+buwI/M7E9mthz4GsEdqJsG23nTdflVYDiln/+XJ3g24FbuvppgNnaReqnk+pwJzKxHUSKUeW26\n+yr0n3qpr3KvzQ3AWyrduS7mwZUa2KYB55IWuj4lrXRtSlrV7NpUoBrYBoI0218LpROuSD3p+pS0\n0rUpaVXTa1OBamArCfpb+xsNrKpzLSL96fqUtNK1KWlV02tTgWpgvwBO6jfSfxTBWKlbE6lIZBtd\nn5JWujYlrWp6bTbls/zMrDDj6ekEc098AngCeMLd7wq32QO4n+ChnV8It/8isCdwnLtvrmvR0jR0\nfUpa6dqUtErDtdmsgWoLpQemLXT3txZtdzDQA5xBMGhtATDV3TVpp9SMrk9JK12bklZpuDabMlCJ\niIiIxEljqEREREQiUqASERERiUiBSkRERCQiBSoRERGRiBSoRERERCJSoBIRERGJSIFKREREJCIF\nKhEREZGIFKhEREREIlKgEhEREYlIgUqkiZnZGjPbYmaHpHF/snP6zEXSQYFKJGEJ/0J0YEuK99eQ\n6vwzTfVnbmbTzOwBM9sYfia5Ababb2bPhdu8amZ/NbMJdS5XpGp6OLJIwszsUeAQ4NA4nnhe4bEP\nBV4DPOzur6Ztf42qnj/TRvnMzex6YD/gPcBYd3+gxDYjgaXAeHf/a51LFIlELVQiTczdH3X3h+L6\nRRz3/mTnGugz3xW4CjDgPwbYZk/gZoUpaUQKVCIJMbMLzGwLQUuGAYVuokKXxyHhdlvM7NXw+wvN\n7F4z2xQu3ydcfqKZfd3MFpvZejN70cweN7O5ZvbmQWoo2TXV75jvNbN7zOwZM3vazBaY2Sn12F+4\n/XFmdquZPWVmz5rZEjP7cP/9lsvMjjKz2WGtL4Y1PGpmPzWzs0tsv0fYbXVf+LlvNrMVZjbDzPbs\nt21ZP9OY69vhMzezO4uOO9DrhmrPs1JmdhSw2t0XAauA95vZfiU2PQ3IRTmWSFJ2TboAkSa2GvgB\nMBnYA5gPPBuu86LvATCzK4FPAHcDtwFHhtsBfBk4FVgJ/BF4ETgaOBt4t5m9z93nl6jBi/axAzOb\nCXwOWATcDhwLvBU4xcw63P2Ptdyfmb013G434C/A/cABwHVm9vqBjjPI8duB3wN7hfv7RVjvQcCZ\nwDDgp0XbHwTcAbwe+CdwD/AC8CZgBsFn2+Hum8K3VPQzjVpf0X77f+b/Bzw6wGHeAfwL8EqE86xU\nB3BX+P23gSuBC4H/r992E4CPV3kMkWS5u1566ZXgi+AX36vAIQOs3xKuzwMnDLDNmcBrSyw/iyBc\nPQEMK/fYRcd8Aji+37rrwvW/ruX+gN2BvvB9l/VbdxLwdGG/FXzWN4T7m1Zi3R7Am/stuyfc/ori\nz48g4N0YHv+GSn+mcdVX6bGAc8Oa1xGM74p0nhWe12vC7/chCJarS2z3qyh/l/TSK8mXuvxEGsdX\n3X1pqRXufoe7P1Fi+S+BucBwgu6USl3m7vf3W/b58Ot4M9ulhvs7h6A16iF3/2LxG9z9XuCaCo8N\nQcsMwK/6r3D3zV7UQmZmbycIbn9w90vd/YWibV8EPkbQmnOeme1bRS2R6quUmZ0KfB/YDExy90fD\n5fU4z2Hu/nK4z6eBHwGHmtlZRfWNBv5c5f5FEqdAJdI4fjbYSjMbEY7h+bqZfcfMvm9m3wfaw02O\nquKYv+y/IAxuGwhaL0bUcH+nEnRl/WSAff2owmMD3Ecwtuk6MzvdzIYOsu07w+P372IDgoADLCEY\nOvGmKmqJWl/ZzOwYgutnCHCeuy8uWl3T8zSzowm6QotdS3CelxQt0/gpaWgaQyXSOHoHWmFmHyUY\nj7IHA49h2qfSA/rAt/w/TXAL/LAa7u+g8OtA5z3g5zGIrwPjgLcRjBl60czuBxYCP3T3FUXbHkbw\nS/8bZvaNQfbpwGurqCVqfWUxs9cC/wvsC0x191v7bVLr8+xg2/ipYEfuy81sMXC6mR3p7n8jGD/1\nsSr2L5IKClQiDSLsftmBmZ1A0P31MvBfBIO4/+7uz4frvwx8muCXZiMaKCBWPJll+JmcaWZvAt4O\nnAKcDJwITDOzGe5+ebj5LuGxFwJrdrLrasJdNfVd5u5fKnd/ZjaM4HpoBa509ytLbFbr8zwFuKnE\n8msJxlZ9ErgUaHH3DVXsXyQVFKhEGt854ddZ7t5TYv0R9SwmRn3h19YB1o+qdsdhl9diADPblWCw\n9neBGWb247DFZG24+Vx3v7baY8VcX7eZ/SSsb1BmZsAtBN10P3f3qQNsWuvz3DvsNuzvxwStqheY\n2Y8JplMQaVgaQyWSvJfCr9X+B2d4+PXv/VeY2f7AGVXuN2l3EbSqTRlg/blxHMTdX3H3G4F7w+Md\nG676v/DPk6vYbdSfaTn17UwP8C6CcVmDfVZRznNQ4fipkuEvHPw+m6Ar8tto/JQ0OAUqkeQ9Hn6t\neF6l0F8IfiGeXzwBo5ntTXBXV1x3oNXbXOAfwDFm9vniFRZMVvqJSndoZh8PJ5nsv/wwoC38Y6Fb\n6+cEj0E51cyuNbOWEu87wMwuKnGoqn6mFdY32H4+BXyKYEqFzuI790qIcp4700G/8VP9fDv82k7Q\n5SjSsPQsP5GEmdklwCzgGYKByBvDVdPcfUM487a7e8kpCsIZpx8ADgaeJJj40wgG+b5IMCD5QqC7\n//QDNsAz58o45kDvi3t/pxNMbjmM4Jb6wsSe4wkmh/xP4CV3L2twvJktB44DHgFWEMyHdADBQPDX\nALe4+weKtj+I4M7EN4TbPkDQRTaM4K7J0cA/3P11/Y4z6M80rvrC9+zw2dm22eN/Dzw8wOHudvfv\nRTnPwZjZvwILgE+6+4ChyswWAPu7+/Hl7lskjTSGSiR53wL2Bs4jmIhzt3D55QTTCcAgs4+7+8Zw\nYPrlBN177ySYN2gewSzXH2PwGcwrXV7t+yren7svMLO3AN0EIepdwF8JWqd+RRContzJfot9DpgI\nvJlgsPc+BK1gdwLfcfftpg5w98fN7ESCQDqFIHCcCDxF0Ar1dYIWnv5K/Uyd7X+mkesrLnWA5aeE\nr4He8z2IdJ47MLODCX42RxCEwDvM7M/AG7308wa/NUiNIg1DLVQi0pDM7IMEY3B+4e7vTroeEWlu\nGkMlIqllZq+1Eg8UNrOTCFpNnODZeSIiiVKXn4ik2bHAb8xsBcEA65cIJqIcQxCmbnT3srqiRERq\nSV1+IpJa4WDpzxA8huZAgnFJTwPLgR+4ezWPnxERiZ0ClYiIiEhEGkMlIiIiEpEClYiIiEhEClQi\nIiIiESlQiYiIiESkQCUiIiISkQKViIiISEQKVCIiIiIRKVCJiIiIRPT/A4LtqALY7QF9AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f667e317a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "from matplotlib import use\n",
    "use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Use scipy's Cholesky decomposition for matrix inversion.\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "# Reset the RNG.\n",
    "numpy.random.seed(1)\n",
    "# Try for various sizes of training samples.\n",
    "TrainSetSize = [5,10,25,50,100,200,400,800]\n",
    "BfValueMed   = []\n",
    "BfValueLower = []\n",
    "BfValueUpper = []\n",
    "Nsimu        = 100\n",
    "for N in TrainSetSize:\n",
    "    # Array for holding results of all simulations.\n",
    "    RawBfValues = numpy.empty(Nsimu)\n",
    "    for s in range(Nsimu):\n",
    "        # Draw x from uniform interval -10,10.\n",
    "        X = numpy.random.uniform(-10, 10, N)\n",
    "        # Create Y=0 plus Gaussian random noise.\n",
    "        Y = 0.0 + numpy.random.normal(0.0, 1.0, N)\n",
    "        # Step 1: Compute the analytic evidence for M_1: f(x) = a_0.\n",
    "        # Build design matrix.\n",
    "        DesignT    = numpy.empty([1,N])\n",
    "        DesignT[0] = 1.0\n",
    "        Design     = DesignT.T\n",
    "        # Define matrix A, vector b and scalar c. Note that theta_0=0.\n",
    "        A = numpy.dot(DesignT, Design) + numpy.identity(1)\n",
    "        b = numpy.dot(DesignT, Y)\n",
    "        c = numpy.dot(Y, Y)\n",
    "        # Use a trick to get inverse matrix from more stable Cholesky decomposition.\n",
    "        cholesky = cho_factor(A)\n",
    "        Ainv     = cho_solve(cholesky, numpy.identity(1))\n",
    "        # Compute log-evidence of first model. Drop irrelevant normalisation constants.\n",
    "        logEvi1 = -0.5*math.log(numpy.linalg.det(A)) - 0.5*c + 0.5*numpy.dot(b, numpy.dot(Ainv, b))\n",
    "        # Step 2: Compute the analytic evidence for M_2: f(x) = a_0+a_1*x.\n",
    "        # Build design matrix.\n",
    "        DesignT    = numpy.empty([2,N])\n",
    "        DesignT[0] = 1.0\n",
    "        DesignT[1] = X\n",
    "        Design     = DesignT.T\n",
    "        # Define matrix A, vector b and scalar c. Note that theta_0=0.\n",
    "        A = numpy.dot(DesignT, Design) + numpy.identity(2)\n",
    "        b = numpy.dot(DesignT, Y)\n",
    "        c = numpy.dot(Y, Y)\n",
    "        # Use a trick to get inverse matrix from more stable Cholesky decomposition.\n",
    "        cholesky = cho_factor(A)\n",
    "        Ainv     = cho_solve(cholesky, numpy.identity(2))\n",
    "        # Compute log-evidence of second model. Drop irrelevant normalisation constants.\n",
    "        logEvi2 = -0.5*math.log(numpy.linalg.det(A)) - 0.5*c + 0.5*numpy.dot(b, numpy.dot(Ainv, b))\n",
    "        # Write Bayes factor (do not forget to exponentiate log-evidences).\n",
    "        RawBfValues[s] = math.exp(logEvi1 - logEvi2)\n",
    "    # Sort the p-values.\n",
    "    RawBfValues = sorted(RawBfValues)\n",
    "    # Get median, lower 16% and upper 84% levels.\n",
    "    BfValueMed.append(numpy.median(RawBfValues))\n",
    "    BfValueLower.append(RawBfValues[int(round(0.16*(Nsimu-1.0)))])\n",
    "    BfValueUpper.append(RawBfValues[int(round(0.84*(Nsimu-1.0)))])\n",
    "# Plot how p-value evolves as N increases.\n",
    "plt.figure(1, figsize=(9,6))\n",
    "plt.plot(TrainSetSize, BfValueMed, 'o', ms=5, color='black')\n",
    "for n in range(len(TrainSetSize)):\n",
    "    plt.plot([TrainSetSize[n], TrainSetSize[n]], [BfValueLower[n],BfValueUpper[n]], '-', lw=1, color='black')\n",
    "X = numpy.array([1,1000])\n",
    "plt.plot(X, 6.0*numpy.sqrt(X), '--', lw=1, color='black')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(r'training set size $N$', fontsize=22)\n",
    "plt.ylabel(r'$P(D|M_1)/P(D|M_2)$', fontsize=22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
